{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Predicting Net Promoter Score (NPS) with NPS verbatims\n",
    "# Xiyan (Jamie) Wang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Indroduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Net Promoter Score** is an index ranging from -100 to 100 that measures the willingness of customers to recommend a company’s products or services to others. It is used as a proxy for gauging the customer’s overall satisfaction with a company’s product or service and the customer’s loyalty to the brand. Customers are surveyed on one single question. They are asked to rate on an 11-point scale the likelihood of recommending the company or brand to a friend or colleague.\n",
    "* ‘Promoters’ answered 9 or 10. They love the company’s products and services. They are the repeat buyers, are the enthusiastic evangelist who recommends the company products and services to other potential buyers. \n",
    "\n",
    "* ‘Detractors’ gave a score lower or equal to 6. They are not particularly thrilled by the product or the service. They, with all likelihood, won’t purchase again from the company, could potentially damage the company’s reputation through negative word of mouth.\n",
    "\n",
    "* ‘Passives’ gave a score of 7 or 8. They are somewhat satisfied but could easily switch to a competitor’s offering if given the opportunity. They probably wouldn’t spread any negative word-of-mouth, but are not enthusiastic enough about your products or services to actually promote them.\n",
    "\n",
    "Sometimes customers are also surveyed on the “why” behind the score, and their answer to such questions are called **\"NPS verbatism\"**. Such verbatims can be used to uncover and quantify what the company does well and what it can fix or improve: be a product issue, a support, or a logistics issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Motivations and goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently many company with NPS capability tend to use text analytics techniques to quantify the NPS vervatism. For example, topic modeling has been used frequently to recognize the topics embedded in the verbatims. However, to my knowledge, there exist little practice to use the quantified text data for prediction of any kinds. \n",
    "\n",
    "While one can argue that gathering data through survey regularly (i.e. through tracking studies) can provide a company with sufficient awareness of it's custmoter's satisfaction level, it is imperitive to understand that it is also possible to predict NPS scores through predictive modeling using real time text data such as social media reviews. \n",
    "\n",
    "In the following excersice, I will use a comparatively small dataset to attemp to set up a predictive model using the verbatims to predict NPS catergories (Promoter/Detractor). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Overview of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>Respondent_Serial</th>\n",
       "      <th>NPS1_1</th>\n",
       "      <th>NPS_Recode</th>\n",
       "      <th>NPS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISP</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>Passive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISP</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISP</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Other options in my community are less desirable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISP</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISP</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Segment  Respondent_Serial  NPS1_1 NPS_Recode  \\\n",
       "0     ISP                 62       7    Passive   \n",
       "1     ISP                 64       3  Detractor   \n",
       "2     ISP                 65      10   Promoter   \n",
       "3     ISP                 66       5  Detractor   \n",
       "4     ISP                 67       5  Detractor   \n",
       "\n",
       "                                                NPS2  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  Other options in my community are less desirable.  \n",
       "3                                               cost  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "raw = pd.read_csv('C:\\\\lda python\\\\Wireline Data for Concept Mining.csv',encoding = \"ISO-8859-1\")\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are only predicting NPS using Text transcript, and we can not get any information from missing NPS2. We subset data with non-missing NPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of non missing data: 54053\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>Respondent_Serial</th>\n",
       "      <th>NPS1_1</th>\n",
       "      <th>NPS_Recode</th>\n",
       "      <th>NPS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISP</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Other options in my community are less desirable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISP</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISP</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>reliability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISP</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>too expensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISP</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Years ago there was a massive virus attack on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Segment  Respondent_Serial  NPS1_1 NPS_Recode  \\\n",
       "2     ISP                 65      10   Promoter   \n",
       "3     ISP                 66       5  Detractor   \n",
       "5     ISP                 69      10   Promoter   \n",
       "6     ISP                 70       5  Detractor   \n",
       "7     ISP                 71       8    Passive   \n",
       "\n",
       "                                                NPS2  \n",
       "2  Other options in my community are less desirable.  \n",
       "3                                               cost  \n",
       "5                                        reliability  \n",
       "6                                      too expensive  \n",
       "7  Years ago there was a massive virus attack on ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw2 = raw.dropna(subset = ['NPS2'])\n",
    "print(\"Size of non missing data:\", raw2.shape[0])\n",
    "raw2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check out how balanced the data are in terms of the dependent variable NPS_recode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPS_Recode</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Promoter</td>\n",
       "      <td>18902</td>\n",
       "      <td>0.349694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Passive</td>\n",
       "      <td>18008</td>\n",
       "      <td>0.333154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detractor</td>\n",
       "      <td>17143</td>\n",
       "      <td>0.317152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NPS_Recode  count  percentage\n",
       "0   Promoter  18902    0.349694\n",
       "1    Passive  18008    0.333154\n",
       "2  Detractor  17143    0.317152"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "NPS_cat = raw2['NPS_Recode'].value_counts()\n",
    "color = sns.color_palette()\n",
    "\n",
    "counts = raw2['NPS_Recode'].value_counts().reset_index()\n",
    "counts.columns = ['NPS_Recode', 'count']\n",
    "counts['percentage'] = counts['count']/54053\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAEFCAYAAAD62n4IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc52e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Interest Level ALONG\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(counts['NPS_Recode'],counts['percentage'], alpha=0.8, color=color[1])\n",
    "plt.ylabel('Percent of data', fontsize=12)\n",
    "plt.xlabel('NPS Catergories', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above distribution we can see that around 35% of the data are promoters. Another 33% are Passive and 32% are Detractors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Use regular expressions to do a find-and-replace\n",
    "raw2.loc[:,'NPS2_nopunc'] = raw2.loc[:,'NPS2'].apply(lambda x: re.sub(\"[^a-zA-Z]\",\" \",x))\n",
    "#to lower case and split to list of word \n",
    "raw2.loc[:,'NPs2_lower'] = raw2.loc[:,'NPS2_nopunc'].apply(lambda x: x.lower()).apply(lambda x: x.split()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stop_words\n",
      "  Using cached stop-words-2015.2.23.1.tar.gz\n",
      "Building wheels for collected packages: stop-words\n",
      "  Running setup.py bdist_wheel for stop-words: started\n",
      "  Running setup.py bdist_wheel for stop-words: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\xiyan_wang\\AppData\\Local\\pip\\Cache\\wheels\\22\\74\\80\\77275c2f9f2f1d9841b51e169a38985640a10fbd2711d10791\n",
      "Successfully built stop-words\n",
      "Installing collected packages: stop-words\n",
      "Successfully installed stop-words-2015.2.23.1\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from \"words\"\n",
    "!pip install stop_words\n",
    "from stop_words import get_stop_words\n",
    "en_stop = get_stop_words('en')\n",
    "raw2.loc[:,'NPs2_stopped'] = raw2['NPs2_lower'].apply(lambda x: [item for item in x if item not in en_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>Respondent_Serial</th>\n",
       "      <th>NPS1_1</th>\n",
       "      <th>NPS_Recode</th>\n",
       "      <th>NPS2</th>\n",
       "      <th>NPS2_nopunc</th>\n",
       "      <th>NPs2_lower</th>\n",
       "      <th>NPs2_stopped</th>\n",
       "      <th>NPS2_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISP</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>Other options in my community are less desirable.</td>\n",
       "      <td>Other options in my community are less desirable</td>\n",
       "      <td>[other, options, in, my, community, are, less,...</td>\n",
       "      <td>[options, community, less, desirable]</td>\n",
       "      <td>[option, commun, less, desir]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISP</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>cost</td>\n",
       "      <td>cost</td>\n",
       "      <td>[cost]</td>\n",
       "      <td>[cost]</td>\n",
       "      <td>[cost]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ISP</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>Promoter</td>\n",
       "      <td>reliability</td>\n",
       "      <td>reliability</td>\n",
       "      <td>[reliability]</td>\n",
       "      <td>[reliability]</td>\n",
       "      <td>[reliabl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ISP</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>Detractor</td>\n",
       "      <td>too expensive</td>\n",
       "      <td>too expensive</td>\n",
       "      <td>[too, expensive]</td>\n",
       "      <td>[expensive]</td>\n",
       "      <td>[expens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ISP</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>Passive</td>\n",
       "      <td>Years ago there was a massive virus attack on ...</td>\n",
       "      <td>Years ago there was a massive virus attack on ...</td>\n",
       "      <td>[years, ago, there, was, a, massive, virus, at...</td>\n",
       "      <td>[years, ago, massive, virus, attack, comcast, ...</td>\n",
       "      <td>[year, ago, massiv, viru, attack, comcast, dis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Segment  Respondent_Serial  NPS1_1 NPS_Recode  \\\n",
       "2     ISP                 65      10   Promoter   \n",
       "3     ISP                 66       5  Detractor   \n",
       "5     ISP                 69      10   Promoter   \n",
       "6     ISP                 70       5  Detractor   \n",
       "7     ISP                 71       8    Passive   \n",
       "\n",
       "                                                NPS2  \\\n",
       "2  Other options in my community are less desirable.   \n",
       "3                                               cost   \n",
       "5                                        reliability   \n",
       "6                                      too expensive   \n",
       "7  Years ago there was a massive virus attack on ...   \n",
       "\n",
       "                                         NPS2_nopunc  \\\n",
       "2  Other options in my community are less desirable    \n",
       "3                                               cost   \n",
       "5                                        reliability   \n",
       "6                                      too expensive   \n",
       "7  Years ago there was a massive virus attack on ...   \n",
       "\n",
       "                                          NPs2_lower  \\\n",
       "2  [other, options, in, my, community, are, less,...   \n",
       "3                                             [cost]   \n",
       "5                                      [reliability]   \n",
       "6                                   [too, expensive]   \n",
       "7  [years, ago, there, was, a, massive, virus, at...   \n",
       "\n",
       "                                        NPs2_stopped  \\\n",
       "2              [options, community, less, desirable]   \n",
       "3                                             [cost]   \n",
       "5                                      [reliability]   \n",
       "6                                        [expensive]   \n",
       "7  [years, ago, massive, virus, attack, comcast, ...   \n",
       "\n",
       "                                        NPS2_stemmed  \n",
       "2                      [option, commun, less, desir]  \n",
       "3                                             [cost]  \n",
       "5                                          [reliabl]  \n",
       "6                                           [expens]  \n",
       "7  [year, ago, massiv, viru, attack, comcast, dis...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "# stem token\n",
    "raw2.loc[:,'NPS2_stemmed'] = raw2['NPs2_stopped'].apply (lambda x:[p_stemmer.stem(item) for item in x])\n",
    "raw2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 2-Gram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a document-term matrix (Bag of Word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning up the documents, we transform the column of verbatims into a document-term matrix, so that the occurance of each word can be quantified and used for learning process. A document-term matrix or term-document matrix is a mathematical matrix that describes the frequency of terms that occur in a collection of documents. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(raw2['NPS2_stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then convert convert tokenized documents to vectors: <type 'list'>\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in raw2['NPS2_stemmed']]\n",
    "print \"Then convert convert tokenized documents to vectors: %s\"% type(corpus)\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a tf-idf corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In information retrieval, tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. The tf-idf value increases proportionally to the number of times a word appears in the document, but is often offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We initialize our TF-IDF transformation tool : <class 'gensim.models.tfidfmodel.TfidfModel'>\n",
      "<gensim.interfaces.TransformedCorpus object at 0x0000000008EBDDA0>\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model\n",
    "print \"We initialize our TF-IDF transformation tool : %s\"%type(tfidf)\n",
    "\n",
    "# corpus tf-idf\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "print corpus_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag-of-words representation with or without a TF-IDF weighting are commonly used in text analytics. It retains a great deal of information, yet it can also be inefficient since many terms may actually represent similar meanings. It can also be confusing since one word can also imply multiple meanings. A bag-of-words representation can also be cumbersome given its high dimentionality. Hence, dimension reduction techniques are usually applied to the document-term matrix to collapse together terms that have the same \"Semantics\", and to provide a lower-dimensional representation of the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two forms of dimensional reduction techniques are used here for such analysis, including: 1) Latent semantic indexing, which uses spectral decomposition to identify a lower-dimensional representation of the origianl matrix. 2) Latent dirichlet allocation, which uses a probabilistic model to find the co-occurence patterns of terms that correspond to semantic topics in a collection of documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel_tfidf = gensim.models.ldamodel.LdaModel(corpus, num_topics=50, id2word = dictionary, passes=20)\n",
    "ldamodel_bow = gensim.models.ldamodel.LdaModel(corpus_tfidf, num_topics=50, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lsamodel_tfidf = gensim.models.lsimodel.LsiModel(corpus, num_topics=50, id2word = dictionary)\n",
    "lsamodel_bow = gensim.models.lsimodel.LsiModel(corpus_tfidf, num_topics=50, id2word = dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the document to Topic weight matrix. Each column here have the \"loadings \" of each document on each topic after dimention reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docTopicProbMat_bow = ldamodel_bow[corpus]\n",
    "docTopicProbMat_tfidf = ldamodel_tfidf[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docTopicProbMat_bow_lsa = lsamodel_bow[corpus]\n",
    "docTopicProbMat_tfidf_lsa = lsamodel_tfidf[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Document Topic Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## bow LDA/LSA\n",
    "probmatrix_bow = []\n",
    "\n",
    "for i in docTopicProbMat_bow:\n",
    "    tmp = [0]*50\n",
    "    for j in i:\n",
    "        tmp[j[0]] = j[1]\n",
    "    probmatrix_bow.append(tmp)\n",
    "\n",
    "df_bow = pd.DataFrame(probmatrix_bow)\n",
    "\n",
    "probmatrix_bow_lsa = []\n",
    "\n",
    "for i in docTopicProbMat_bow_lsa:\n",
    "    tmp = [0]*50\n",
    "    for j in i:\n",
    "        tmp[j[0]] = j[1]\n",
    "    probmatrix_bow_lsa.append(tmp)\n",
    "\n",
    "df_bow_lsa = pd.DataFrame(probmatrix_bow_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TFIDF LDA/LSA\n",
    "probmatrix_tfidf = []\n",
    "\n",
    "for i in docTopicProbMat_tfidf:\n",
    "    tmp = [0]*50\n",
    "    for j in i:\n",
    "        tmp[j[0]] = j[1]\n",
    "    probmatrix_tfidf.append(tmp)\n",
    "\n",
    "df_tfidf = pd.DataFrame(probmatrix_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "probmatrix_tfidf_lsa = []\n",
    "\n",
    "for i in docTopicProbMat_tfidf_lsa:\n",
    "    tmp = [0]*50\n",
    "    for j in i:\n",
    "        tmp[j[0]] = j[1]\n",
    "    probmatrix_tfidf_lsa.append(tmp)\n",
    "\n",
    "df_tfidf_lsa = pd.DataFrame(probmatrix_tfidf_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32, 0.5099999999999999)]\n"
     ]
    }
   ],
   "source": [
    "print docTopicProbMat_tfidf[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach NPS (label) to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "Y_promoter = (raw2['NPS_Recode'] == \"Promoter\")\n",
    "Y_promoter.head()\n",
    "Y_detractor = (raw2['NPS_Recode'] == \"Detractor\")\n",
    "Y_detractor.head()\n",
    "Y = raw2['NPS_Recode'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will used our different set-ups to predict NPS category (both promoter and detractor) and find the optimal combination of dimension-reduction + training methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promoter - LDA/LSA - BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model,metrics\n",
    "cv = cross_validation.ShuffleSplit(Y_promoter.size, n_iter=50, test_size=.1, random_state=0)\n",
    "accuracy_vec = []\n",
    "insample_accuracy_vec = []\n",
    "for k,(train, test) in enumerate(cv):\n",
    "    clf = linear_model.LogisticRegression(C=1., class_weight = 'balanced')\n",
    "    clf.fit(df_bow.iloc[train], Y_promoter.iloc[train])\n",
    "    pred = clf.predict(df_bow.iloc[test])\n",
    "    accuracy = metrics.accuracy_score(Y_promoter.iloc[test],pred)     \n",
    "    accuracy_vec.append(accuracy)   \n",
    "    insample_pred = clf.predict(df_bow.iloc[train])\n",
    "    insample_accuracy = metrics.accuracy_score(Y_promoter.iloc[train],insample_pred)     \n",
    "    insample_accuracy_vec.append(insample_accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_vec_lsa = []\n",
    "insample_accuracy_vec_lsa = []\n",
    "for k,(train, test) in enumerate(cv):\n",
    "    clf = linear_model.LogisticRegression(C=1.)  #, class_weight = 'balanced')\n",
    "    clf.fit(df_bow_lsa.iloc[train], Y_promoter.iloc[train])\n",
    "    pred_lsa = clf.predict(df_bow_lsa.iloc[test])\n",
    "    accuracy_lsa = metrics.accuracy_score(Y_promoter.iloc[test],pred)     \n",
    "    accuracy_vec_lsa.append(accuracy_lsa) \n",
    "    insample_pred_lsa = clf.predict(df_bow.iloc[train])\n",
    "    insample_accuracy_lsa = metrics.accuracy_score(Y_promoter.iloc[train],insample_pred)     \n",
    "    insample_accuracy_vec_lsa.append(insample_accuracy_lsa) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: mean in-sample accuracy of 50 CV is 0.6816\n",
      "LDA: mean accuracy of 50 CV is 0.6806\n",
      "LDA: std of 50 CV is 0.0053\n",
      "LSA: mean in-sample accuracy of 50 CV is 0.5175\n",
      "LSA: mean accuracy of 50 CV is 0.5146\n",
      "LSA: std of 50 CV is 0.0234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2319, 1160],\n",
       "       [ 616, 1311]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np = np.array(accuracy_vec).mean()  ## get the confidence interval for this accuracy\n",
    "insample_accuracy_np = np.array(insample_accuracy_vec).mean()  ## get the confidence interval for this accuracy\n",
    "accuracy_std_np = np.array(accuracy_vec).std()\n",
    "\n",
    "accuracy_np_lsa = np.array(accuracy_vec_lsa).mean()  ## get the confidence interval for this accuracy\n",
    "insample_accuraty_np_lsa = np.array(insample_accuracy_vec_lsa).mean()\n",
    "accuracy_std_np_lsa = np.array(accuracy_vec_lsa).std()\n",
    "\n",
    "print \"LDA: mean in-sample accuracy of 50 CV is\", round(insample_accuracy_np,4)\n",
    "print \"LDA: mean accuracy of 50 CV is\", round(accuracy_np,4)\n",
    "print \"LDA: std of 50 CV is\", round(accuracy_std_np,4)\n",
    "\n",
    "print \"LSA: mean in-sample accuracy of 50 CV is\", round(insample_accuraty_np_lsa,4)\n",
    "print \"LSA: mean accuracy of 50 CV is\", round(accuracy_np_lsa,4)\n",
    "print \"LSA: std of 50 CV is\", round(accuracy_std_np_lsa,4)\n",
    "\n",
    "# View confusion matrix\n",
    "metrics.confusion_matrix(y_true=Y_promoter.iloc[test],  # True labels\n",
    "                         y_pred=pred) # Predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like LSA is not a good idea compared to the accuracy of the LDA model. While in-sample accuracy and out-of-sample accuracy are similar and both are around 0.68, we are safe from the plague of over-fitting. For simplicity, the following code would not include in-sample accuracy calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Promoter - LDA - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model,metrics\n",
    "cv = cross_validation.ShuffleSplit(Y_promoter.size, n_iter=50, test_size=.1, random_state=0)\n",
    "accuracy_vec = []\n",
    "for k,(train, test) in enumerate(cv):\n",
    "    clf = linear_model.LogisticRegression(C=1., class_weight = 'balanced')\n",
    "    clf.fit(df_tfidf.iloc[train], Y_promoter.iloc[train])\n",
    "    pred = clf.predict(df_tfidf.iloc[test])\n",
    "    accuracy = metrics.accuracy_score(Y_promoter.iloc[test],pred)      ## fix me\n",
    "    accuracy_vec.append(accuracy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy of 50 CV is 0.6885\n",
      "std of 50 CV is 0.0052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2540,  939],\n",
       "       [ 751, 1176]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np = np.array(accuracy_vec).mean()  ## get the confidence interval for this accuracy\n",
    "accuracy_std_np = np.array(accuracy_vec).std()\n",
    "print \"mean accuracy of 50 CV is\", round(accuracy_np,4)\n",
    "print \"std of 50 CV is\", round(accuracy_std_np,4)\n",
    "\n",
    "# View confusion matrix\n",
    "metrics.confusion_matrix(y_true=Y_promoter.iloc[test],  # True labels\n",
    "                         y_pred=pred) # Predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like TFIDF is getting similar results for Promoter prediction with LDA dimentsion reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've only used logistics regression, which is a linear classifier. Let's try Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv = cross_validation.ShuffleSplit(Y_promoter.size, n_iter=1, test_size=.1, random_state=0)\n",
    "accuracy_vec = []\n",
    "insample_accuracy_vec = []\n",
    "for k,(train, test) in enumerate(cv):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(df_tfidf.iloc[train],Y_promoter.iloc[train]) \n",
    "    pred = rf.predict(df_tfidf.iloc[test])\n",
    "    accuracy = metrics.accuracy_score(Y_promoter.iloc[test],pred)      ## fix me\n",
    "    accuracy_vec.append(accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy of 50 CV is 0.8356\n",
      "std of 50 CV is 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3152,  346],\n",
       "       [ 543, 1365]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np = np.array(accuracy_vec).mean()  ## get the confidence interval for this accuracy\n",
    "accuracy_std_np = np.array(accuracy_vec).std()\n",
    "print \"mean accuracy of 50 CV is\", round(accuracy_np,4)\n",
    "print \"std of 50 CV is\", round(accuracy_std_np,4)\n",
    "\n",
    "# View confusion matrix\n",
    "metrics.confusion_matrix(y_true=Y_promoter.iloc[test],  # True labels\n",
    "                         y_pred=pred) # Predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>NPS_Recode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  NPS_Recode\n",
       "0  False        3498\n",
       "1   True        1908"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts =Y_promoter.iloc[test].value_counts().reset_index()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that reandom forest is giving out a much better prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detractor - LDA - BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy of 50 CV is 0.6794\n",
      "std of 50 CV is 0.0073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1436, 2043],\n",
       "       [1419,  508]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model,metrics\n",
    "cv = cross_validation.ShuffleSplit(Y_detractor.size, n_iter=50, test_size=.1, random_state=0)\n",
    "accuracy_vec = []\n",
    "for k,(train, test) in enumerate(cv):\n",
    "    clf = linear_model.LogisticRegression(C=1., class_weight = 'balanced')\n",
    "    clf.fit(df_bow.iloc[train], Y_detractor.iloc[train])\n",
    "    pred = clf.predict(df_bow.iloc[test])\n",
    "    accuracy = metrics.accuracy_score(Y_detractor.iloc[test],pred)      ## fix me\n",
    "    accuracy_vec.append(accuracy)  \n",
    "accuracy_np = np.array(accuracy_vec).mean()  ## get the confidence interval for this accuracy\n",
    "accuracy_std_np = np.array(accuracy_vec).std()\n",
    "print \"mean accuracy of 50 CV is\", round(accuracy_np,4)\n",
    "print \"std of 50 CV is\", round(accuracy_std_np,4)\n",
    "# View confusion matrix\n",
    "metrics.confusion_matrix(y_true=Y_promoter.iloc[test],  # True labels\n",
    "                         y_pred=pred) # Predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detractor - LDA - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy of 50 CV is 0.6635\n",
      "std of 50 CV is 0.0068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1310, 2169],\n",
       "       [1352,  575]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model,metrics\n",
    "cv = cross_validation.ShuffleSplit(Y_detractor.size, n_iter=50, test_size=.1, random_state=0)\n",
    "accuracy_vec = []\n",
    "for k,(train, test) in enumerate(cv):\n",
    "    clf = linear_model.LogisticRegression(C=1., class_weight = 'balanced')\n",
    "    clf.fit(df_tfidf.iloc[train], Y_detractor.iloc[train])\n",
    "    pred = clf.predict(df_tfidf.iloc[test])\n",
    "    accuracy = metrics.accuracy_score(Y_detractor.iloc[test],pred)      ## fix me\n",
    "    accuracy_vec.append(accuracy)  \n",
    "accuracy_np = np.array(accuracy_vec).mean()  ## get the confidence interval for this accuracy\n",
    "accuracy_std_np = np.array(accuracy_vec).std()\n",
    "print \"mean accuracy of 50 CV is\", round(accuracy_np,4)\n",
    "print \"std of 50 CV is\", round(accuracy_std_np,4)\n",
    "# View confusion matrix\n",
    "metrics.confusion_matrix(y_true=Y_promoter.iloc[test],  # True labels\n",
    "                         y_pred=pred) # Predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It would seem that LDA prediction for promoter have similar accuracy for BOW and DFIDF set-ups. let's again try the rf model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detractor - LDA - Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv = cross_validation.ShuffleSplit(Y_detractor.size, n_iter=50, test_size=.1, random_state=0)\n",
    "accuracy_vec = []\n",
    "for k,(train, test) in enumerate(cv):\n",
    "    rf = RandomForestClassifier(class_weight = 'balanced')\n",
    "    rf.fit(df_tfidf.iloc[train],Y_detractor.iloc[train]) \n",
    "    pred = rf.predict(df_tfidf.iloc[test])\n",
    "    accuracy = metrics.accuracy_score(Y_detractor.iloc[test],pred)      ## fix me\n",
    "    accuracy_vec.append(accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False,  True], dtype=bool)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy of 50 CV is 0.8783\n",
      "std of 50 CV is 0.004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3436,  264],\n",
       "       [ 434, 1272]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np = np.array(accuracy_vec).mean()  ## get the confidence interval for this accuracy\n",
    "accuracy_std_np = np.array(accuracy_vec).std()\n",
    "print \"mean accuracy of 50 CV is\", round(accuracy_np,4)\n",
    "print \"std of 50 CV is\", round(accuracy_std_np,4)\n",
    "# View confusion matrix\n",
    "metrics.confusion_matrix(y_true=Y_detractor.iloc[test],  # True labels\n",
    "                         y_pred=pred) # Predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most important topics in predictions are: [26 17  1 47  7 21 28 18 22 13]\n",
      "topit 0 word 0 : channel\n",
      "topit 0 word 1 : littl\n",
      "topit 0 word 2 : chang\n",
      "topit 0 word 3 : far\n",
      "topit 0 word 4 : complet\n",
      "topit 1 word 0 : price\n",
      "topit 1 word 1 : high\n",
      "topit 1 word 2 : servic\n",
      "topit 1 word 3 : keep\n",
      "topit 1 word 4 : go\n",
      "topit 2 word 0 : provid\n",
      "topit 2 word 1 : servic\n",
      "topit 2 word 2 : mediacom\n",
      "topit 2 word 3 : none\n",
      "topit 2 word 4 : tech\n",
      "topit 3 word 0 : will\n",
      "topit 3 word 1 : come\n",
      "topit 3 word 2 : even\n",
      "topit 3 word 3 : day\n",
      "topit 3 word 4 : wait\n",
      "topit 4 word 0 : time\n",
      "topit 4 word 1 : us\n",
      "topit 4 word 2 : warner\n",
      "topit 4 word 3 : sinc\n",
      "topit 4 word 4 : took\n",
      "topit 5 word 0 : ok\n",
      "topit 5 word 1 : one\n",
      "topit 5 word 2 : demand\n",
      "topit 5 word 3 : hour\n",
      "topit 5 word 4 : show\n",
      "topit 6 word 0 : connect\n",
      "topit 6 word 1 : program\n",
      "topit 6 word 2 : gener\n",
      "topit 6 word 3 : overpr\n",
      "topit 6 word 4 : na\n",
      "topit 7 word 0 : custom\n",
      "topit 7 word 1 : servic\n",
      "topit 7 word 2 : poor\n",
      "topit 7 word 3 : speak\n",
      "topit 7 word 4 : support\n",
      "topit 8 word 0 : verizon\n",
      "topit 8 word 1 : happi\n",
      "topit 8 word 2 : servic\n",
      "topit 8 word 3 : w\n",
      "topit 8 word 4 : dont\n",
      "topit 9 word 0 : better\n",
      "topit 9 word 1 : frontier\n",
      "topit 9 word 2 : deal\n",
      "topit 9 word 3 : sometim\n",
      "topit 9 word 4 : now\n"
     ]
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1][0:10]\n",
    "\n",
    "print \"most important topics in predictions are:\", indices\n",
    "for i in range(len(indices)):\n",
    "    topics = ldamodel_tfidf.show_topic(i, topn = 8)\n",
    "    for w in range(5):\n",
    "        print \"topit\", i, \"word\", w, \":\", topics[w][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26    25735\n",
      "17    41910\n",
      "1     51958\n",
      "47     2960\n",
      "7     13458\n",
      "21     1548\n",
      "28     6064\n",
      "18     1293\n",
      "22     4966\n",
      "13    18584\n",
      "dtype: int64\n",
      "Everything is for the most part of high quality.\n"
     ]
    }
   ],
   "source": [
    "## Get example documents for each most important topics \n",
    "index_maxtopic = df_tfidf.idxmax(axis = 0)\n",
    "imp_index = index_maxtopic[indices]\n",
    "print imp_index\n",
    "print raw['NPS2'][15349]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv = cross_validation.ShuffleSplit(Y.size, n_iter=50, test_size=.1, random_state=0)\n",
    "accuracy_vec = []\n",
    "for k,(train, test) in enumerate(cv):\n",
    "    rf = RandomForestClassifier(class_weight = 'balanced')\n",
    "    rf.fit(df_tfidf.iloc[train],Y.iloc[train]) \n",
    "    pred = rf.predict(df_tfidf.iloc[test])\n",
    "    accuracy = metrics.accuracy_score(Y.iloc[test],pred)      ## fix me\n",
    "    accuracy_vec.append(accuracy) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy of 50 CV is 0.7555\n",
      "std of 50 CV is 0.0063\n"
     ]
    }
   ],
   "source": [
    "accuracy_np = np.array(accuracy_vec).mean()  ## get the confidence interval for this accuracy\n",
    "accuracy_std_np = np.array(accuracy_vec).std()\n",
    "print \"mean accuracy of 50 CV is\", round(accuracy_np,4)\n",
    "print \"std of 50 CV is\", round(accuracy_std_np,4)\n",
    "# View confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "docs = raw2['NPS2_stemmed']\n",
    "\n",
    "# Lemmatize all words in documents.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "docs = [[lemmatizer.lemmatize(token) for token in doc] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "bigram  = Phrases(docs)\n",
    "for idx in range(len(docs)):\n",
    "    for token in bigram[docs[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            docs[idx].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x1b105710>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "dictionary_2g = corpora.Dictionary(docs)\n",
    "dictionary_2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then convert convert tokenized documents to vectors: <class 'list'>\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus_2g = [dictionary_2g.doc2bow(text) for text in docs]\n",
    "print(\"Then convert convert tokenized documents to vectors: %s\"% type(corpus_2g))\n",
    "print(corpus_2g[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We initialize our TF-IDF transformation tool : <class 'gensim.models.tfidfmodel.TfidfModel'>\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "tfidf_2g = models.TfidfModel(corpus_2g) # step 1 -- initialize a model\n",
    "print(\"We initialize our TF-IDF transformation tool : %s\"%type(tfidf_2g))\n",
    "# corpus tf-idf\n",
    "corpus_tfidf_2g = tfidf_2g[corpus_2g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ldamodel_tfidf_2g = gensim.models.ldamodel.LdaModel(corpus_tfidf_2g, num_topics=50, id2word = dictionary_2g, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docTopicProbMat_tfidf_2g = ldamodel_tfidf_2g[corpus_tfidf_2g]\n",
    "## TFIDF LDA/LSA\n",
    "probmatrix_tfidf_2g = []\n",
    "\n",
    "for i in docTopicProbMat_tfidf_2g:\n",
    "    tmp = [0]*50\n",
    "    for j in i:\n",
    "        tmp[j[0]] = j[1]\n",
    "    probmatrix_tfidf_2g.append(tmp)\n",
    "\n",
    "df_tfidf_2g = pd.DataFrame(probmatrix_tfidf_2g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiyan_wang\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "Y_promoter = (raw2['NPS_Recode'] == \"Promoter\")\n",
    "Y_promoter.head()\n",
    "Y_detractor = (raw2['NPS_Recode'] == \"Detractor\")\n",
    "Y_detractor.head()\n",
    "Y = raw2['NPS_Recode'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv = cross_validation.ShuffleSplit(Y_promoter.size, n_iter=1, test_size=.1, random_state=0)\n",
    "accuracy_vec = []\n",
    "insample_accuracy_vec = []\n",
    "for k,(train, test) in enumerate(cv):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(df_tfidf_2g.iloc[train],Y_promoter.iloc[train]) \n",
    "    pred = rf.predict(df_tfidf_2g.iloc[test])\n",
    "    accuracy = metrics.accuracy_score(Y_promoter.iloc[test],pred)      ## fix me\n",
    "    accuracy_vec.append(accuracy)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy of 50 CV is 0.8352\n",
      "std of 50 CV is 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3163,  335],\n",
       "       [ 556, 1352]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_np = np.array(accuracy_vec).mean()  ## get the confidence interval for this accuracy\n",
    "accuracy_std_np = np.array(accuracy_vec).std()\n",
    "print (\"mean accuracy of 50 CV is\", round(accuracy_np,4))\n",
    "print (\"std of 50 CV is\", round(accuracy_std_np,4))\n",
    "\n",
    "# View confusion matrix\n",
    "metrics.confusion_matrix(y_true=Y_promoter.iloc[test],  # True labels\n",
    "                         y_pred=pred) # Predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
